{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e62eddd2",
   "metadata": {},
   "source": [
    "<h1>Multi-layer Perceptron - MNIST</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d07805-1cd2-45e4-afea-a7e7cbdf9063",
   "metadata": {},
   "source": [
    "Creiamo una rete MLP per riconoscere le 10 cifre numeriche scritte a mano. Per fare questo usiamo un dataset già presente in <strong>scikit-learn</strong>: MNIST database (<em>Modified National Institute of Standards and Technology database</em>). Questo database contiene una vasta base di dati di cifre scritte a mano da studenti delle scuole superiori e da impiegati dell’Ufficio Censimento degli USA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24655988",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784')\n",
    "\n",
    "print(\"Campi del dataset\\n\",mnist.keys())\n",
    "print(mnist['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8325e2cd-7063-4c0d-9738-9b46a63e9cb1",
   "metadata": {},
   "source": [
    "Dopo aver letto la descrizione capiamo che i primi 60 000 campioni vengono proposti per il training set mentre i successivi 10 000 per il test set. I dati sono memorizzati come immagini 28x28 in scala di grigio, pertanto ogni cifra è rappresentata come un array di 784 numeri interi compresi tra 0 e 255 per rappresentare le gradazioni di grigio (nero=0, bianco=255)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4efc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y = mnist.target\n",
    "X = mnist.data\n",
    "print(X.shape) # 70000 campioni di 784 pixel = 28x28 in gradazioni di grigio\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8306e726-3e17-4069-8b2a-4b994836ff67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# disegnamo un campione\n",
    "plt.imshow(X.loc[0].values.reshape(28, 28), cmap='gray')\n",
    "plt.title(f\"Label: {y[0]}\") \n",
    "plt.axis(\"off\")  # rimuove gli assi\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bb875f-236e-48fd-af11-a0fbbd0f68e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X / 255   # normalizziamo i dati ottenendo valori tutti compresi tra 0 e 1 (opzionale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89076ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:],y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4a11d7-3403-4ddc-802e-c7d8ec9a7194",
   "metadata": {},
   "source": [
    "Passiamo ad addestrare la rete scegliendo un solo livello nascosto con 50 nodi. Utilizziamo il parametro <kbd>verbose = True</kbd> per vedere l’andamento dell’apprendimento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3730b3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(50,), max_iter=20, verbose=True, random_state=1, learning_rate_init=0.1)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "print(\"Training set score: %f\" % mlp.score(X_train, y_train))\n",
    "print(\"Test set score: %f\" % mlp.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215173b1-e54f-43b0-92dd-5877b2304700",
   "metadata": {},
   "source": [
    "Notiamo dall’output che il processo termina prima delle 20 epoche perché c’è un peggioramento per 10 epoche consecutive, a partire dall’iterazione numero 6. Infatti se guardiamo l’andamento dell’errore, osserviamo che esso raggiunge il suo minimo dopo 5 epoche. Siccome ci interessa conoscere l’accuratezza, fermiamo il processo in questo punto e vediamo che valore essa assume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14cd633",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(50,), max_iter=5, verbose=True, random_state=1, learning_rate_init=0.1)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "print(\"Training set score: %f\" % mlp.score(X_train, y_train))\n",
    "print(\"Test set score: %f\" % mlp.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a714d75-1c86-48e2-8482-a4b16a43fe90",
   "metadata": {},
   "source": [
    "Dall’output capiamo che sebbene l’algoritmo non converga, l’accuratezza è leggermente migliorata rispetto a quella ottenuta prima, dopo 16 iterazioni. Fino a ora abbiamo usato l’algoritmo di ottimizzazione di default <b>adam</b>. Adesso usiamone un altro: l’<b>sgd</b>, cioè lo <i>stocastic gradient descent</i>. La libreria <strong>scikit-learn</strong> prevede anche un terzo algoritmo di training l’L-BFGS, la cui trattazione però esula dallo scopo di questo testo. Qui di seguito troviamo il codice in cui usiamo sgd e il corrispondente output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f39a27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(50,), max_iter=20, verbose=True, random_state=1, learning_rate_init=.1, solver = \"sgd\")\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "print(\"Training set score: %f\" % mlp.score(X_train, y_train))\n",
    "print(\"Test set score: %f\" % mlp.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a405cf67-6a61-409a-8f3e-fc5255dad7ca",
   "metadata": {},
   "source": [
    "Dall’output capiamo che è andata decisamente meglio! Inoltre osserviamo che l’errore sta continuando a scendere. Questo vuol dire che stiamo rischiando l’overfitting? Per accertarcene impostiamo un numero diverso di epoche e controlliamo di volta in volta l’accuratezza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329b1835",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 3  # numero iniziale di epoche\n",
    "stop = 30  # numero finale di epoche \n",
    "passo = 2  # passo incrementale\n",
    "\n",
    "vEpochs = np.arange(start, stop+1, passo)\n",
    "yTrain = []  #lista dell'accuratezza sui dati di train per disegnare un grafico\n",
    "yTest = []   #lista dell'accuratezza sui dati di test per disegnare un grafico\n",
    "\n",
    "for e in vEpochs:\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(50,), max_iter=e, random_state=1, learning_rate_init=.1, solver = \"sgd\") \n",
    "    mlp.fit(X_train, y_train)\n",
    "    print(e)\n",
    "    accTrain = mlp.score(X_train, y_train)\n",
    "    print(\"Training set score: %f\" % accTrain)\n",
    "    yTrain.append(accTrain)\n",
    "    accTest = mlp.score(X_test, y_test)\n",
    "    print(\"Test set score: %f\" % accTest)\n",
    "    yTest.append(accTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92236bb4-7deb-414c-8f61-9334f8679763",
   "metadata": {},
   "source": [
    "Creiamo il grafico corrispondente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98f5025",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grafico dell'accuratezza \n",
    "plt.plot(vEpochs, yTrain, c='b', label = 'Train' )\n",
    "plt.plot(vEpochs, yTest, c='g', label = 'Test')\n",
    "plt.xlabel(\"epoche\", fontsize=15)\n",
    "plt.ylabel(\"accuratezza\", fontsize=15)\n",
    "plt.tick_params(axis='both', labelsize='15')\n",
    "plt.legend(fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcfa046-caa9-4ff3-afd3-61cc4340ae7e",
   "metadata": {},
   "source": [
    "Sia dagli output sia dal grafico notiamo che il numero di epoche ottimale è 21, perché proseguendo con l’addestramento si cade nell’overfitting: le performance sul set di training migliorano, mentre quelle sul set di test peggiorano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e387a25-6dee-46c8-b67d-763bba3fce22",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(50,), max_iter=21, random_state=1, learning_rate_init=.1, solver = \"sgd\") \n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6ae77f-ec2f-4f1c-9702-bbe29a184b9d",
   "metadata": {},
   "source": [
    "Proviamo a testare il nostro modello"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9afd81",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3c0e3c-e55a-437e-929e-4802898c05d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# carica l'immagine in scala di grigi e ridimensionala a 28x28\n",
    "image = cv2.imread(\"3.png\", cv2.IMREAD_GRAYSCALE)\n",
    "image = cv2.resize(image, (28, 28))\n",
    "# normalizza i valori\n",
    "image = image / 255 \n",
    "# converte l'immagine in un vettore 1x784\n",
    "x_sample = image.flatten().reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d403ec-f994-48ca-8172-114318938ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from PIL import Image\n",
    "\n",
    "image = Image.open(\"3.png\").convert(\"L\")  # \"L\" = grayscale\n",
    "image = image.resize((28, 28))\n",
    "image_array = np.array(image)  \n",
    "image_array = image_array / 255 \n",
    "x_sample = image_array.flatten().reshape(1, -1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f017bbfe-5647-450d-a7fe-33d60ebc1b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sample = mlp.predict(x_sample)\n",
    "print(y_sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
